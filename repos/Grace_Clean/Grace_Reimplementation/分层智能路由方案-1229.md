分层智能路由方案

* * *

分层智能路由：确定版本实现方案（NSFNET，统一容量）
=================================

1\. 实验环境与确定性参数
--------------

### 1.1 仿真器与拓扑

*   仿真器：`ns.py` 离散事件仿真
*   训练拓扑：**NSFNET**


### 1.2 链路与队列模型（统一容量，单位秒）

*   **端口容量（统一值）**：
    $$
    C = 10{,}000\ \text{bit/ms} = 10^7\ \text{bit/s} = 10\ \text{Mbps}
    $$
*   **传播时延（每 hop）**：
    $$
    d_{\text{prop}} = 10\ \text{ms} = 0.01\ \text{s}
    $$
*   分组大小：
    $$
    S = 1500\ \text{B} = 12{,}000\ \text{bit}
    $$
*   **传输时延（每 hop）**：
    $$
    d_{\text{tx}}=\frac{S}{C}=\frac{12000}{10^7}=0.0012\ \text{s}
    $$
*   因此每跳基准时延（不含排队）：
    $$
    d_{\text{hop,base}}=d_{\text{prop}}+d_{\text{tx}}=0.0112\ \text{s}
    $$
*   排队：每个出端口一个 FIFO 队列（drop-tail）

### 1.3 缓冲与防环路

*   Buffer：**512KB = 524,288B**（约 349 个 1500B 包）
*   TTL/hop-limit：**启用**（防环路与安全约束）

### 1.4 流量与 episode（固定）

*   并发流数：**F\_base = 3**
*   NSFNET 三对源宿（训练/标定固定对）：
    *   (0,10) 长距离对角线
    *   (1,11) 与 (0,10) 路径重叠
    *   (3,13) 另一条对角线
*   Episode 结构（单位秒）：
    *   warmup：0.5 s
    *   measure：3.0 s
    *   drain：1.0 s
    *   total：4.5 s
*   指标统计窗口：**仅在 measure 窗口 \[0.5, 3.5\] s 统计**

### 1.5 四档负载（单条流 pps，固定）

*   light = 380 pps
*   medium = 420 pps
*   heavy = 460 pps
*   burst = 560 pps

* * *

2\. 方法概述：分层（Bandit 选簇 + PPO 簇内逐跳）
---------------------------------

*   上层：**Contextual Bandit（LinUCB）** 选择“路径簇”（route-style option）
*   下层：**Masked PPO** 在选定簇的约束下逐跳选择出端口（micro-control）
*   优化目标（综合评分）：latency 0.5 + throughput(goodput) 0.4 + loss 0.1

* * *

3\. 路径簇构建（离线，确定且简化）
-------------------

### 3.1 候选路径

对每个 (s,d)：

*   枚举 **K = 20** 条候选简单路径（k-shortest 或无环枚举）

### 3.2 路径风格特征（同质容量下的确定版本）

由于容量同质（10 Mbps），`avg_capacity` 与 `bottleneck_capacity` 对所有路径退化为常数，因此**不作为聚类主特征**。采用以下静态拓扑特征即可稳定形成“风格簇”：

*   hop\_count
*   stretch\_to\_shortest（相对最短路 hop stretch）
*   overlap\_to\_shortest（与最短路的链路重叠比例，用于区分“共享 vs 分离”风格）

### 3.3 聚类与簇数

*   聚类算法：**KMeans**
*   簇数：**M = 6**
*   arm = cluster id ∈ {1..6}

> 论文表述：路径簇提供“风格先验”，用于缩小探索空间与增强可解释性。

* * *

4\. 上层 Bandit（确定：按 mode 分桶 LinUCB）
----------------------------------

### 4.1 决策粒度

*   按 **flow-window** 做簇选择：
    $$
    \Delta t_{\text{win}}=0.1\ \text{s}
    $$
*   一个窗口内该 flow 固定选择的 cluster。

### 4.2 分桶与算法

*   **四个 mode 各自独立一套 LinUCB**（light/medium/heavy/burst）
*   LinUCB 选择：
    $$
    k^*=\arg\max_k \left(\hat\theta_k^\top x + \alpha\sqrt{x^\top A_k^{-1}x}\right),\ \alpha=1.0
    $$

### 4.3 Context（简化但足够）

对每个 (flow, window) 构造 x：

*   mode one-hot（4 维）
*   该 flow 上一窗口统计：avg\_latency、delivery\_ratio、goodput  
    （可选：簇内平均 queue\_ratio、utilization；若实现方便可加，否则可省）

### 4.4 Bandit 回报（窗口级）

在窗口内统计（measure 口径）：

*    $L$ ：该 flow 窗口内 delivered 包平均时延
*    $T$ ：该 flow 窗口内 goodput（delivered bits / 0.1s）
*    $P$ ：该 flow 窗口内 loss rate

组合：

$$
r^{bandit}=0.5 f_L(L)+0.4 f_T(T)+0.1 f_P(P)
$$

* * *

5\. 下层 PPO（确定：masked per-hop routing）
-------------------------------------

### 5.1 MDP 与动作

*   Step：包到达节点 u，选择一个出端口 u→v
*   终止：delivered 或 dropped/TTL 到期

### 5.2 Mask（簇约束，带安全 fallback）

*   严格 mask：仅允许选择属于所选簇路径集合中的“合法下一跳端口”
*   若严格 mask 为空（避免死锁）：
    1.  允许所有使 `dist(v,dst) < dist(u,dst)` 的端口（朝目的地推进）
    2.  若仍为空：允许除返回上一跳外的端口

### 5.3 观测（局部可迁移，确定字段）

对每个邻接端口 e=(u→v)：

*   queue\_ratio(e)
*   utilization(e)（短窗）
*   dist\_to\_dst(v)（静态最短路 hop 距离）
*   delta\_dist  
    全局附加：
*   mode one-hot
*   TTL\_remaining（或 hop\_count）

> 同质容量下 capacity 不提供区分度，可不输入（或当常数输入也不影响）。

### 5.4 PPO 奖励（确定且简化）

*   每跳 shaping：
    
$$
r_{step}= -0.6\cdot queue\_ratio(e)-0.4\cdot util(e)-0.2\cdot \max(0,\Delta dist)
$$
*   终止奖励：
    *   delivered：+1
    *   dropped：−1

（若你们已验证“终局对齐项”能提升稳定性，可加；但为简化与可复现，主文可以只保留上述版本。）

* * *

6\. cap-normalization（确定：按 mode 标定，跨负载稳定）
-----------------------------------------

为消除四档负载下指标量纲差异，对每个 mode 用 baseline（ECMP 或 SP）在 NSFNET 上跑若干 episode，计算 measure 窗口的：

*    $L_{cap}$ ：latency 的 95 分位
*    $T_{cap}$ ：goodput 的 95 分位
*    $P_{cap}$ ：loss 的 95 分位（下限 1e-3）

归一化：

*    $f_L(L)=\mathrm{clip}(1-L/L_{cap},0,1)$ 
*    $f_T(T)=\mathrm{clip}(T/T_{cap},0,1)$ 
*    $f_P(P)=1-\mathrm{clip}(P/P_{cap},0,1)$ 

该归一化用于 Bandit 回报（以及可选的 PPO 终局对齐项）。

* * *

7\. 训练流程（确定：三段式 + 课程学习）
-----------------------

### 7.1 三段式训练

1.  **PPO 预训练**：上层簇均匀随机选取（覆盖 6 簇），训练 PPO 学稳定逐跳转发与避拥塞
2.  **Bandit 训练**：冻结 PPO，仅训练每个 mode 的 LinUCB 做簇选择
3.  **联合微调**：小学习率微调 PPO，Bandit 继续在线更新

### 7.2 课程学习（混合采样递进）

*   Stage 0：light 100%
*   Stage 1：light 70% + medium 30%
*   Stage 2：light 40% + medium 40% + heavy 20%
*   Stage 3：light 25% + medium 35% + heavy 25% + burst 15%

推进条件可在论文中简化为“当综合评分稳定提升并达到预设阈值时进入下一阶段”。


* * *
